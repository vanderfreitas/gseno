{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romul\\AppData\\Local\\Temp\\ipykernel_26320\\1885318389.py:13: RuntimeWarning: Could not add vertex ids, there is already an 'id' vertex attribute. at src/io/graphml.c:492\n",
      "  g = Graph.Read_GraphML(mydir+\"\\\\data\\\\networks\\\\weighted_graph_all_modes.GraphML\")\n"
     ]
    }
   ],
   "source": [
    "from igraph import Graph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "import gseno\n",
    "import os \n",
    "from matplotlib import rc\n",
    "# Open the GraphML file and create a Graph object from it\n",
    "mydir = os.getcwd()\n",
    "g = Graph.Read_GraphML(mydir+\"\\\\data\\\\networks\\\\weighted_graph_all_modes.GraphML\")\n",
    "Ncs = [1,2,3]\n",
    "Csn_ncs = []\n",
    "Anm_ncs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cases(csv_file, n):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(\n",
    "        csv_file,\n",
    "        encoding='utf-8',\n",
    "        sep=',',\n",
    "        usecols=['ibgeID', 'newCases', 'totalCases', 'date'],\n",
    "        dtype={'ibgeID': int}\n",
    "    )\n",
    "\n",
    "    # Convert 'date' column to datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "\n",
    "    # Filter the DataFrame based on the given conditions\n",
    "    filtered_df = df[(df['totalCases'] >= n) & (df['newCases'] >= 1) & (df['ibgeID'] > 1000)]\n",
    "    \n",
    "    # Remove duplicate rows based on 'ibgeID'\n",
    "    filtered_df = filtered_df.drop_duplicates(subset='ibgeID', keep='first')\n",
    "    return filtered_df\n",
    "\n",
    "def filter_records(df1, df2):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing the ibgeIDs present in both input DataFrames.\n",
    "    \"\"\"\n",
    "    # Extract the ibgeIDs from both DataFrames\n",
    "    ibgeIDs_df1 = set(df1['ibgeID'])\n",
    "    ibgeIDs_df2 = set(df2['ibgeID'])\n",
    "\n",
    "    # Find the intersection of both sets of ibgeIDs\n",
    "    common_ibgeIDs = ibgeIDs_df1.intersection(ibgeIDs_df2)\n",
    "    \n",
    "    # Filter df2 to keep only rows with common ibgeIDs\n",
    "    filtered_df2 = df2[df2['ibgeID'].isin(common_ibgeIDs)]\n",
    " \n",
    "    # Sort the filtered DataFrame by 'date' and remove duplicate rows based on 'ibgeID' and 'date'\n",
    "    filtered_df2 = (\n",
    "        filtered_df2\n",
    "        [['ibgeID', 'date']]\n",
    "        .sort_values(by='date', ascending=True)\n",
    "        .drop_duplicates(subset=['ibgeID', 'date'])\n",
    "    )\n",
    "\n",
    "    # Return the filtered DataFrame\n",
    "    return filtered_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex 2903 with geocode 3165206.0 is not in shared_cities\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for nc in Ncs:  \n",
    "    # Set vertex labels\n",
    "    g.vs['label'] = np.linspace(1, g.vcount(), g.vcount(), dtype=int).tolist()\n",
    "\n",
    "    # Inverse weights for betweenness calculation\n",
    "    g.es['w_inv'] = 1.0 / np.array(g.es['weight'])\n",
    "\n",
    "    # Calculate various graph metrics\n",
    "    g.vs['betweenness'] = g.betweenness(vertices=None, directed=False, cutoff=None, weights='w_inv')\n",
    "    g.vs['clustering'] = g.transitivity_local_undirected()\n",
    "    g.vs['strength'] = g.strength(weights=\"weight\")\n",
    "    g.vs['closeness'] = g.closeness(vertices=None, mode='all', cutoff=None, weights='w_inv', normalized=True)\n",
    "    g.vs['eigenvector'] = g.evcent(directed=False, scale=True, weights='w_inv', return_eigenvalue=False)\n",
    "\n",
    "    # Create a DataFrame with graph metrics\n",
    "    graph_df = pd.DataFrame({\n",
    "        'label': g.vs['label'],\n",
    "        'ibgeID': g.vs[\"geocode\"],\n",
    "        'betweenness': g.vs['betweenness'],\n",
    "        'clustering': g.vs['clustering'],\n",
    "        'strength': g.vs['strength'],\n",
    "        'closeness': g.vs['closeness'],\n",
    "        'eigenvector': g.vs['eigenvector']\n",
    "    })\n",
    "\n",
    "    # Filter the cases DataFrame\n",
    "    filter_df = filter_cases(mydir+\"\\\\data\\\\preprocessed\\\\cases-brazil-cities-time_2020.csv\", nc)\n",
    "    # Get the shared ibgeIDs between the graph DataFrame and filtered cases DataFrame\n",
    "    shared_cities = filter_records(graph_df, filter_df)\n",
    "    shared_cities = shared_cities.rename(columns={'ibgeID': 'label', 'date': 'rank'})\n",
    "    shared_cities['label'] = shared_cities['label'].astype(float)\n",
    "\n",
    "    shared_cities_set = set(shared_cities['label'])\n",
    "\n",
    "    # Filter vertices to keep only those in shared_cities\n",
    "    vertices_to_keep = []\n",
    "    for v in g.vs:\n",
    "        geocode = v['geocode']\n",
    "        if geocode in shared_cities_set:\n",
    "            vertices_to_keep.append(v.index)\n",
    "        else:\n",
    "            print(f\"Vertex {v.index} with geocode {geocode} is not in shared_cities\")\n",
    "\n",
    "    g.vs['label'] = g.vs['geocode']\n",
    "    subgraph = g.subgraph(vertices_to_keep)\n",
    "\n",
    "    # First approach: Compute the intersections between sets of nodes ordered by a certain metric and its rank from the input DataFrame\n",
    "    results_df = gseno.csn(\n",
    "        graph=subgraph, \n",
    "        sorted_nodes_df=shared_cities   \n",
    "    )\n",
    "    Csn_ncs.append(results_df)\n",
    "\n",
    "\n",
    "    # Second approach: Accumulate the nodes' metrics from the sorted nodes by rank (from the input DataFrame)\n",
    "    # The output for each metric is normalized to be within [0,1]\n",
    "    results_df = gseno.anm(\n",
    "        graph=subgraph, \n",
    "        sorted_nodes_df=shared_cities\n",
    "    )\n",
    "    Anm_ncs.append(results_df)\n",
    "\n",
    "\n",
    "    #setUp_comparsion_table(min_cases[0])\n",
    "    #print(degrees_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csn_ncs\n",
      "[             degrees  betweenness  clustering  strength  closeness_w   eignv_w\n",
      "2020-02-25  1.000000     0.000000    0.000000  1.000000     0.000000  1.000000\n",
      "2020-03-05  0.500000     0.000000    0.000000  0.500000     0.000000  0.500000\n",
      "2020-03-06  0.250000     0.250000    0.000000  0.250000     0.000000  0.250000\n",
      "2020-03-07  0.500000     0.166667    0.000000  0.333333     0.000000  0.333333\n",
      "2020-03-08  0.500000     0.125000    0.000000  0.250000     0.000000  0.250000\n",
      "...              ...          ...         ...       ...          ...       ...\n",
      "2020-10-12  0.999257     0.999257    0.999257  0.999257     0.999257  0.999257\n",
      "2020-10-20  0.999443     0.999443    0.999443  0.999443     0.999443  0.999443\n",
      "2020-10-27  0.999628     0.999628    0.999628  0.999628     0.999628  0.999628\n",
      "2020-11-06  0.999814     0.999814    0.999814  0.999814     0.999814  0.999814\n",
      "2020-11-13  1.000000     1.000000    1.000000  1.000000     1.000000  1.000000\n",
      "\n",
      "[194 rows x 6 columns],              degrees  betweenness  clustering  strength  closeness_w   eignv_w\n",
      "2020-02-28  1.000000     0.000000    0.000000  1.000000     0.000000  1.000000\n",
      "2020-03-07  0.500000     0.000000    0.000000  0.500000     0.000000  0.500000\n",
      "2020-03-08  0.333333     0.000000    0.000000  0.333333     0.000000  0.333333\n",
      "2020-03-11  0.250000     0.250000    0.000000  0.500000     0.000000  0.500000\n",
      "2020-03-12  0.666667     0.222222    0.000000  0.333333     0.000000  0.333333\n",
      "...              ...          ...         ...       ...          ...       ...\n",
      "2020-11-23  0.999071     0.999071    0.999071  0.999071     0.999071  0.999071\n",
      "2020-11-26  0.999257     0.999257    0.999257  0.999257     0.999257  0.999257\n",
      "2020-11-27  0.999443     0.999443    0.999443  0.999443     0.999443  0.999443\n",
      "2020-11-28  0.999814     0.999814    0.999814  0.999814     0.999814  0.999814\n",
      "2020-12-04  1.000000     1.000000    1.000000  1.000000     1.000000  1.000000\n",
      "\n",
      "[215 rows x 6 columns],              degrees  betweenness  clustering  strength  closeness_w   eignv_w\n",
      "2020-03-04  1.000000     0.000000    0.000000  1.000000     0.000000  1.000000\n",
      "2020-03-11  0.500000     0.000000    0.000000  0.500000     0.000000  0.500000\n",
      "2020-03-12  0.250000     0.250000    0.000000  0.250000     0.000000  0.250000\n",
      "2020-03-13  0.200000     0.400000    0.000000  0.400000     0.000000  0.200000\n",
      "2020-03-14  0.750000     0.375000    0.000000  0.500000     0.000000  0.375000\n",
      "...              ...          ...         ...       ...          ...       ...\n",
      "2020-11-28  0.998698     0.998698    0.998698  0.998698     0.998698  0.998698\n",
      "2020-12-01  0.998884     0.998884    0.998884  0.998884     0.998884  0.998884\n",
      "2020-12-02  0.999257     0.999257    0.999257  0.999257     0.999257  0.999257\n",
      "2020-12-04  0.999814     0.999814    0.999814  0.999814     0.999814  0.999814\n",
      "2020-12-17  1.000000     1.000000    1.000000  1.000000     1.000000  1.000000\n",
      "\n",
      "[227 rows x 6 columns]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Csn_ncs\")\n",
    "print(Csn_ncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anm_ncs\n",
      "[             degrees  betweenness  clustering  strength  closeness_w   eignv_w\n",
      "2020-02-25  0.011154     0.024371    0.000007  0.011318     0.000286  0.007686\n",
      "2020-03-05  0.011932     0.024628    0.000066  0.011855     0.000517  0.008309\n",
      "2020-03-06  0.018780     0.037561    0.000113  0.019186     0.001069  0.013860\n",
      "2020-03-07  0.023154     0.050880    0.000135  0.024489     0.001429  0.018231\n",
      "2020-03-08  0.025597     0.056453    0.000240  0.027119     0.001950  0.020234\n",
      "...              ...          ...         ...       ...          ...       ...\n",
      "2020-10-12  0.999908     1.000000    0.999246  0.999877     0.999205  0.999975\n",
      "2020-10-20  0.999916     1.000000    0.999246  0.999920     0.999450  0.999975\n",
      "2020-10-27  0.999939     1.000000    0.999536  0.999946     0.999665  0.999994\n",
      "2020-11-06  0.999985     1.000000    0.999710  0.999989     0.999834  0.999999\n",
      "2020-11-13  1.000000     1.000000    1.000000  1.000000     1.000000  1.000000\n",
      "\n",
      "[194 rows x 6 columns],              degrees  betweenness  clustering  strength  closeness_w   eignv_w\n",
      "2020-02-28  0.011154     0.024371    0.000007  0.011318     0.000286  0.007686\n",
      "2020-03-07  0.014482     0.030046    0.000033  0.014789     0.000567  0.010121\n",
      "2020-03-08  0.018001     0.037304    0.000054  0.018650     0.000837  0.013238\n",
      "2020-03-11  0.022368     0.050623    0.000076  0.023950     0.001125  0.017609\n",
      "2020-03-12  0.037591     0.089901    0.000243  0.039242     0.002497  0.032718\n",
      "...              ...          ...         ...       ...          ...       ...\n",
      "2020-11-23  0.999702     0.999714    0.998831  0.999723     0.999074  0.999953\n",
      "2020-11-26  0.999748     0.999778    0.999044  0.999750     0.999253  0.999955\n",
      "2020-11-27  0.999763     0.999778    0.999334  0.999756     0.999353  0.999958\n",
      "2020-11-28  0.999947     1.000000    0.999820  0.999958     0.999789  0.999993\n",
      "2020-12-04  1.000000     1.000000    1.000000  1.000000     1.000000  1.000000\n",
      "\n",
      "[215 rows x 6 columns],              degrees  betweenness  clustering  strength  closeness_w   eignv_w\n",
      "2020-03-04  0.011155     0.024360    0.000007  0.011319     0.000286  0.007686\n",
      "2020-03-11  0.014483     0.030036    0.000033  0.014790     0.000567  0.010121\n",
      "2020-03-12  0.021263     0.056155    0.000081  0.022476     0.001127  0.016002\n",
      "2020-03-13  0.024584     0.075596    0.000104  0.028479     0.001415  0.017784\n",
      "2020-03-14  0.035724     0.103691    0.000187  0.040321     0.002257  0.029767\n",
      "...              ...          ...         ...       ...          ...       ...\n",
      "2020-11-28  0.999618     0.999714    0.998396  0.999689     0.998853  0.999930\n",
      "2020-12-01  0.999634     0.999714    0.998686  0.999695     0.998953  0.999934\n",
      "2020-12-02  0.999725     0.999778    0.999073  0.999734     0.999207  0.999951\n",
      "2020-12-04  0.999962     1.000000    0.999739  0.999978     0.999854  0.999993\n",
      "2020-12-17  1.000000     1.000000    1.000000  1.000000     1.000000  1.000000\n",
      "\n",
      "[227 rows x 6 columns]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Anm_ncs\")\n",
    "print(Anm_ncs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
